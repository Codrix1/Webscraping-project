{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wb87eo4iqzhW"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "car_groups = [\"car\", \"imported-car\"]"
      ],
      "metadata": {
        "id": "Uh04ZLCQq3Lc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "MtjLYoqNq3tY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrap_cars():\n",
        "  car_names = []\n",
        "  car_prices = []\n",
        "  car_images = []\n",
        "  car_link = []\n",
        "  car_review = []\n",
        "  car_category = []\n",
        "  car_company = []\n",
        "  for i in range(1, 30):\n",
        "      time.sleep(5)\n",
        "      page_to_scrape = requests.get(f\"https://eg.hatla2ee.com/en/new-car/search?vehicle_type=1&make=&model=0&body=&transmission=&priceMin=2&priceMax=\"+ str(i))\n",
        "      print(page_to_scrape.status_code)\n",
        "      soup = BeautifulSoup(page_to_scrape.text, 'html.parser')\n",
        "      car_conatiner = soup.findAll('div', {'class': 'nCarList_contain'})\n",
        "      for car in car_conatiner:\n",
        "\n",
        "        car_name = car.find('div', {'class': 'nCarListData_head'}).text.strip()\n",
        "        car_names.append(car_name)\n",
        "\n",
        "        car_prices.append(car.find('div', {'class': 'nCarListData_prices_elem'}).text.strip())\n",
        "\n",
        "        url = car.find('a').get('href')\n",
        "\n",
        "        car_link.append(url)\n",
        "\n",
        "        car_images.append(car.find('img', {'class': 'lazy'}).get(\"data-nCarListImg_wrap\"))\n",
        "\n",
        "        car_page = requests.get(f\"https://eg.hatla2ee.com/en/new-car/search?vehicle_type=1&make=&model=0&body=&transmission=&priceMin=2&priceMax=/{url}\")\n",
        "        car_p = BeautifulSoup(car_page.text, 'html.parser')\n",
        "        print(car_page.status_code)\n",
        "\n",
        "        car_category.append(car_p.findAll('span', {'property': 'name'})[1].text)\n",
        "\n",
        "        review = car_p.find('div', {'class': 'reviewsStarsWrap'})\n",
        "        try:\n",
        "          number = review.find('strong').text\n",
        "          car_review.append(number)\n",
        "        except:\n",
        "          car_review.append(None)\n",
        "\n",
        "        car_name = car_name.split(\"\")\n",
        "        car_company.append(car_name[0])\n",
        "\n",
        "  cars_scraped = [car_names , car_prices , car_review ,  car_category , car_images , car_company]\n",
        "  df = pd.DataFrame({'CarName': car_names,\n",
        "                    'Price': car_prices,\n",
        "                    'Reviews': car_review,\n",
        "                    'Category': car_category,\n",
        "                    'CarImage':car_images,\n",
        "                    'CarCompany':car_company,\n",
        "                    })\n",
        "  df.to_excel(excel_writer = \"/content/sample_data/cars.xlsx\")\n",
        "\n",
        "scrap_cars()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HE5iZdMq6yM",
        "outputId": "61693689-b7b8-489f-ec11-af823572b093"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ]
        }
      ]
    }
  ]
}